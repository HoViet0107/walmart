{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from etl.spark_initializer import SparkInitializer\n",
    "from etl.extractor.extractor import DataFrameExtractor\n",
    "from etl.tranform.transform import CustomerDataTransformer,PurchaseHistoryDataTransformer,ProductDataTransformer\n",
    "from etl.validator_data import ValidatorImpl\n",
    "from etl.load.loader import LoadDataToMysql\n",
    "import os\n",
    "from etl.sql_executor import MysqlExecutor\n",
    "# Set SPARK_CLASSPATH to include JARs\n",
    "os.environ[\"SPARK_CLASSPATH\"] = os.path.abspath(\"jars/hadoop-aws-3.3.4.jar\") + \";\" + os.path.abspath(\"jars/aws-java-sdk-bundle-1.12.262.jar\")\n",
    "\n",
    "# Reset and initialize Spark session\n",
    "SparkInitializer._spark = None\n",
    "spark = SparkInitializer.get_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Configuration:\n",
      "spark.driver.port: 62728\n",
      "spark.driver.extraJavaOptions: -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n",
      "spark.hadoop.fs.s3a.secret.key: mbEHEER/07OjGFAE3JY6l9JpEaXP3aDaQITuQ4+c\n",
      "spark.app.name: Walmart Fashion ETL\n",
      "spark.executor.id: driver\n",
      "spark.app.submitTime: 1743663842170\n",
      "spark.app.startTime: 1743663842403\n",
      "spark.hadoop.fs.s3a.impl: org.apache.hadoop.fs.s3a.S3AFileSystem\n",
      "spark.sql.warehouse.dir: file:/C:/Users/ADMIN/Documents/_1_My_work/python_workspace/walmart/spark-warehouse\n",
      "spark.app.id: local-1743663844169\n",
      "spark.rdd.compress: True\n",
      "spark.executor.extraJavaOptions: -Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/jdk.internal.ref=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false\n",
      "spark.serializer.objectStreamReset: 100\n",
      "spark.master: local[*]\n",
      "spark.submit.pyFiles: \n",
      "spark.submit.deployMode: client\n",
      "spark.hadoop.fs.s3a.endpoint: s3.ap-southeast-2.amazonaws.com\n",
      "spark.hadoop.fs.s3a.access.key: AKIAW3MD6NNXKRSJI4NH\n",
      "spark.ui.showConsoleProgress: true\n",
      "spark.driver.host: MSI\n",
      "AWS Access Key: AKIAW3MD6NNXKRSJI4NH\n",
      "AWS Secret Key: ***\n",
      "S3 Bucket: walmartbucketpj\n"
     ]
    }
   ],
   "source": [
    "# Debugging Spark Configuration\n",
    "print(\"Spark Configuration:\")\n",
    "for key, value in spark.sparkContext.getConf().getAll():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Debugging AWS Credentials\n",
    "from etl.config.aws_config import AWSConfig\n",
    "aws_config = AWSConfig()\n",
    "print(f\"AWS Access Key: {aws_config.access_key}\")\n",
    "print(f\"AWS Secret Key: {'***' if aws_config.secret_key else None}\")\n",
    "print(f\"S3 Bucket: {aws_config.bucket_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extractor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded fashion purchase data\n",
      "+-----------+--------------+---------------+--------+-------------+-------------+--------------+\n",
      "|customer_id|item_purchased|purchase_amount|quantity|date_purchase|review_rating|payment_method|\n",
      "+-----------+--------------+---------------+--------+-------------+-------------+--------------+\n",
      "|       4115|         Tunic|         2456.0|       3|   2023-07-11|          2.0|   Credit Card|\n",
      "|       4019|      Tank Top|         2102.0|       2|   2023-03-23|          4.1|          Cash|\n",
      "|       4097|      Leggings|         3126.0|       4|   2023-03-15|          3.2|          Cash|\n",
      "+-----------+--------------+---------------+--------+-------------+-------------+--------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Successfully loaded customer data\n",
      "+-----------+----------+---------+------+-------------------+--------------------+------------+-------------------+------------+-----------+\n",
      "|customer_id|first_name|last_name|gender|      date_of_birth|               email|phone_number|        signup_date|     address|       city|\n",
      "+-----------+----------+---------+------+-------------------+--------------------+------------+-------------------+------------+-----------+\n",
      "|       3997|    Robert|    Smith|Female|1994-06-14 21:40:27|jane.davis1@mail.com|634-106-4981|2016-10-16 17:23:25|8465 Main St|San Antonio|\n",
      "|       4101|     Emily|   Garcia|Female|1989-09-21 17:56:31|robert.williams2@...|386-635-5998|2021-04-04 14:24:06| 305 Main St|   New York|\n",
      "|       3986|   Jessica|    Brown|  Male|1984-01-21 21:43:13|emily.davis3@mail...|627-341-5213|2018-04-22 04:51:57| 5725 Oak St|    Chicago|\n",
      "+-----------+----------+---------+------+-------------------+--------------------+------------+-------------------+------------+-----------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Successfully loaded product data\n",
      "+--------+-----------+\n",
      "|    item|   category|\n",
      "+--------+-----------+\n",
      "|Camisole|       Tops|\n",
      "|Leggings|    Bottoms|\n",
      "|  Bowtie|Accessories|\n",
      "+--------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extract data from S3 with error handling\n",
    "try:\n",
    "    fas_purchase_df = (DataFrameExtractor()\n",
    "                        .extract('csv', 'raw/fashion_purchase_history.csv'))\n",
    "    print(\"Successfully loaded fashion purchase data\")\n",
    "    fas_purchase_df.show(3)\n",
    "    \n",
    "    customer_df = (DataFrameExtractor()\n",
    "                        .extract('csv', 'raw/customer.csv'))\n",
    "    print(\"Successfully loaded customer data\")\n",
    "    customer_df.show(3)\n",
    "    \n",
    "    product_df = (DataFrameExtractor()\n",
    "                        .extract('csv', 'raw/products.csv'))\n",
    "    print(\"Successfully loaded product data\")\n",
    "    product_df.show(3)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading data from S3: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transfrom**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mData type:\n",
      "root\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- date_of_birth: timestamp (nullable = true)\n",
      " |-- email: string (nullable = true)\n",
      " |-- phone_number: string (nullable = true)\n",
      " |-- signup_date: timestamp (nullable = true)\n",
      " |-- address: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- item_purchased: string (nullable = true)\n",
      " |-- purchase_amount: double (nullable = true)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- date_purchase: date (nullable = true)\n",
      " |-- review_rating: double (nullable = true)\n",
      " |-- payment_method: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- item: string (nullable = true)\n",
      " |-- category: string (nullable = true)\n",
      "\n",
      "\u001b[1mNull:\n",
      "+-----------+----------+---------+------+-------------+-----+------------+-----------+-------+----+\n",
      "|customer_id|first_name|last_name|gender|date_of_birth|email|phone_number|signup_date|address|city|\n",
      "+-----------+----------+---------+------+-------------+-----+------------+-----------+-------+----+\n",
      "|          0|         1|        0|     1|            1|    2|           1|          0|      1|   2|\n",
      "+-----------+----------+---------+------+-------------+-----+------------+-----------+-------+----+\n",
      "\n",
      "+-----------+--------------+---------------+--------+-------------+-------------+--------------+\n",
      "|customer_id|item_purchased|purchase_amount|quantity|date_purchase|review_rating|payment_method|\n",
      "+-----------+--------------+---------------+--------+-------------+-------------+--------------+\n",
      "|          0|             0|              8|       0|            0|            5|             0|\n",
      "+-----------+--------------+---------------+--------+-------------+-------------+--------------+\n",
      "\n",
      "+----+--------+\n",
      "|item|category|\n",
      "+----+--------+\n",
      "|   0|       1|\n",
      "+----+--------+\n",
      "\n",
      "\u001b[1mDuplicate values:\n",
      "+-----------+----------+---------+------+-------------------+---------------+\n",
      "|customer_id|first_name|last_name|gender|      date_of_birth|duplicate_count|\n",
      "+-----------+----------+---------+------+-------------------+---------------+\n",
      "|       4054|   William|    Davis|Female|1995-06-26 03:31:42|              2|\n",
      "|       4101|     Emily|   Garcia|Female|1989-09-21 17:56:31|              2|\n",
      "|       4070|      John| Martinez|Female|1971-06-18 20:39:32|              2|\n",
      "+-----------+----------+---------+------+-------------------+---------------+\n",
      "\n",
      "+-----------+--------------+-------------+---------------+\n",
      "|customer_id|item_purchased|date_purchase|duplicate_count|\n",
      "+-----------+--------------+-------------+---------------+\n",
      "|       4107|      Swimsuit|   2023-07-02|              2|\n",
      "|       4064|       Sandals|   2022-10-08|              2|\n",
      "+-----------+--------------+-------------+---------------+\n",
      "\n",
      "+----+--------+---------------+\n",
      "|item|category|duplicate_count|\n",
      "+----+--------+---------------+\n",
      "+----+--------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# kiểm tra kiểu dữ liệu\n",
    "print('\\033[1m' +'Data type:')\n",
    "customer_df.printSchema()\n",
    "fas_purchase_df.printSchema()\n",
    "product_df.printSchema()\n",
    "\n",
    "# Check missing value\n",
    "print('\\033[1m' + 'Null:')\n",
    "ValidatorImpl().check_null_values(customer_df)\n",
    "ValidatorImpl().check_null_values(fas_purchase_df)\n",
    "ValidatorImpl().check_null_values(product_df)\n",
    "\n",
    "# Check duplicate value\n",
    "print('\\033[1m' +'Duplicate values:')\n",
    "ValidatorImpl().check_duplicate_records(customer_df,['customer_id', 'first_name', 'last_name', 'gender', 'date_of_birth'])\n",
    "ValidatorImpl().check_duplicate_records(fas_purchase_df,['customer_id', 'item_purchased', 'date_purchase'])\n",
    "ValidatorImpl().check_duplicate_records(product_df,['item', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Change data type:\n",
    "    - date_of_birth: TimeStamp -> Date\n",
    "    - date_purchase: Date -> Timestamp\n",
    "    - review_rating: Double -> Floatx\n",
    "'''\n",
    "cleand_customer_df = CustomerDataTransformer().transform(customer_df)\n",
    "\n",
    "cleand_fas_purchase_df = PurchaseHistoryDataTransformer().transform(fas_purchase_df)\n",
    "\n",
    "cleand_product_df = ProductDataTransformer().transform(product_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- first_name: string (nullable = false)\n",
      " |-- last_name: string (nullable = false)\n",
      " |-- gender: string (nullable = false)\n",
      " |-- date_of_birth: date (nullable = true)\n",
      " |-- email: string (nullable = false)\n",
      " |-- phone_number: string (nullable = false)\n",
      " |-- signup_date: timestamp (nullable = true)\n",
      " |-- address: string (nullable = false)\n",
      " |-- city: string (nullable = false)\n",
      "\n",
      "root\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- item_purchased: string (nullable = true)\n",
      " |-- purchase_amount: double (nullable = false)\n",
      " |-- quantity: integer (nullable = true)\n",
      " |-- date_purchase: timestamp (nullable = true)\n",
      " |-- review_rating: float (nullable = false)\n",
      " |-- payment_method: string (nullable = true)\n",
      "\n",
      "root\n",
      " |-- item: string (nullable = true)\n",
      " |-- category: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check data type\n",
    "cleand_customer_df.printSchema()\n",
    "cleand_fas_purchase_df.printSchema()\n",
    "cleand_product_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-------------+---------------+\n",
      "|customer_id|first_name|last_name|gender|date_of_birth|duplicate_count|\n",
      "+-----------+----------+---------+------+-------------+---------------+\n",
      "+-----------+----------+---------+------+-------------+---------------+\n",
      "\n",
      "+-----------+--------------+-------------+---------------+\n",
      "|customer_id|item_purchased|date_purchase|duplicate_count|\n",
      "+-----------+--------------+-------------+---------------+\n",
      "+-----------+--------------+-------------+---------------+\n",
      "\n",
      "+----+--------+---------------+\n",
      "|item|category|duplicate_count|\n",
      "+----+--------+---------------+\n",
      "+----+--------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check duplicate value\n",
    "ValidatorImpl().check_duplicate_records(cleand_customer_df,['customer_id', 'first_name', 'last_name', 'gender', 'date_of_birth'])\n",
    "ValidatorImpl().check_duplicate_records(cleand_fas_purchase_df,['customer_id', 'item_purchased', 'date_purchase'])\n",
    "ValidatorImpl().check_duplicate_records(cleand_product_df,['item', 'category'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-------------+--------------------+------------+-------------------+-------------+-------+\n",
      "|customer_id|first_name|last_name|gender|date_of_birth|               email|phone_number|        signup_date|      address|   city|\n",
      "+-----------+----------+---------+------+-------------+--------------------+------------+-------------------+-------------+-------+\n",
      "|       3964|      Alex|  Johnson|Female|   1972-07-14|robert.williams87...|291-285-3647|2017-09-17 14:04:33|  7255 Oak St|Phoenix|\n",
      "|       3970|      Alex|    Jones|Female|   1981-10-08|jane.williams34@m...|869-802-7565|2015-07-10 17:08:42|5623 Maple St|Chicago|\n",
      "|       3995|      Alex|    Jones|  Male|   1997-02-05|sarah.martinez133...|924-800-7391|2019-09-13 14:21:15| 5180 Main St|Houston|\n",
      "+-----------+----------+---------+------+-------------+--------------------+------------+-------------------+-------------+-------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+-----------+--------------+---------------+--------+-------------------+-------------+--------------+\n",
      "|customer_id|item_purchased|purchase_amount|quantity|      date_purchase|review_rating|payment_method|\n",
      "+-----------+--------------+---------------+--------+-------------------+-------------+--------------+\n",
      "|       3957|      Backpack|          157.0|       1|2023-06-02 00:00:00|          5.0|          Cash|\n",
      "|       3957|        Blouse|          183.0|       1|2023-03-09 00:00:00|          2.1|   Credit Card|\n",
      "|       3957|      Camisole|          147.0|       2|2022-11-04 00:00:00|          4.7|          Cash|\n",
      "+-----------+--------------+---------------+--------+-------------------+-------------+--------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+--------+-----------+\n",
      "|    item|   category|\n",
      "+--------+-----------+\n",
      "|Camisole|       Tops|\n",
      "|Leggings|    Bottoms|\n",
      "|  Bowtie|Accessories|\n",
      "+--------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleand_customer_df.show(3)\n",
    "cleand_fas_purchase_df.show(3)\n",
    "cleand_product_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Creation table success!\n",
      "✅ Creation table success!\n",
      "✅ Creation table success!\n"
     ]
    }
   ],
   "source": [
    "## Create customer, product and puchase_history_stagging table \n",
    "sql_statements =[\n",
    "    \"\"\"\n",
    "    CREATE TABLE customer(\n",
    "        customer_id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "        first_name VARCHAR(20),\n",
    "        last_name VARCHAR(20),\n",
    "        gender VARCHAR(10),\n",
    "        date_of_birth DATE,\n",
    "        email VARCHAR(50),\n",
    "        phone_number VARCHAR(12),\n",
    "        signup_date TIMESTAMP, \n",
    "        address VARCHAR(255),\n",
    "        city VARCHAR(50)    \n",
    "    )\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE product (\n",
    "        item VARCHAR(50) PRIMARY KEY,\n",
    "        category VARCHAR(50)\n",
    "    )\n",
    "    \"\"\",\n",
    "    \"\"\"\n",
    "    CREATE TABLE purchase_history_stagging (\n",
    "        purchase_id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "        customer_id INT,\n",
    "        item_purchased VARCHAR(50),\n",
    "        purchase_amount DOUBLE,\n",
    "        quantity INT,\n",
    "        date_purchase TIMESTAMP,\n",
    "        review_rating FLOAT,\n",
    "        payment_method VARCHAR(15)\n",
    "       )   \n",
    "    \"\"\"    \n",
    "]\n",
    "message = '✅ Creation table success!' \n",
    "error_message = '❌ Error:'\n",
    "for statement in sql_statements:\n",
    "    try:\n",
    "        MysqlExecutor().execute([statement], message, error_message)\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing statement: {statement}\")\n",
    "        print(f\"Error details: {e}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data to Mysql database\n",
    "db_config = {\n",
    "    'mode': 'append',\n",
    "    'jdbc_url': 'jdbc:mysql://localhost:3306/walmart'\n",
    "}\n",
    "connection_properties = {\n",
    "    'user': 'root',\n",
    "    'password': '12345',\n",
    "    'driver': 'com.mysql.cj.jdbc.Driver'\n",
    "}\n",
    "\n",
    "customer_table_name = 'customer'\n",
    "LoadDataToMysql().load_to_db(cleand_customer_df, customer_table_name, db_config, connection_properties)\n",
    "\n",
    "product_table_name = 'product'\n",
    "LoadDataToMysql().load_to_db(cleand_product_df, product_table_name, db_config, connection_properties)\n",
    "\n",
    "purchase_table_name = 'purchase_history_stagging'\n",
    "LoadDataToMysql().load_to_db(cleand_fas_purchase_df, purchase_table_name, db_config, connection_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+---------------+--------+-------------------+-------------+--------------+\n",
      "|customer_id|item_purchased|purchase_amount|quantity|      date_purchase|review_rating|payment_method|\n",
      "+-----------+--------------+---------------+--------+-------------------+-------------+--------------+\n",
      "|       3958|         Tunic|           64.0|       4|2023-06-17 00:00:00|          1.1|          Cash|\n",
      "|       3962|        Poncho|          184.0|       3|2023-09-25 00:00:00|          2.6|          Cash|\n",
      "|       3963|        Poncho|          184.0|       2|2023-03-02 00:00:00|          1.6|   Credit Card|\n",
      "|       3965|        Poncho|          176.0|       1|2023-09-28 00:00:00|          3.6|          Cash|\n",
      "|       3970|         Tunic|          166.0|       1|2023-02-02 00:00:00|          3.1|   Credit Card|\n",
      "|       3972|         Tunic|          126.0|       3|2022-11-08 00:00:00|          3.8|   Credit Card|\n",
      "|       3976|         Tunic|          140.0|       4|2022-12-31 00:00:00|          4.5|   Credit Card|\n",
      "|       3978|        Poncho|          139.0|       1|2023-01-05 00:00:00|          3.2|          Cash|\n",
      "|       3978|        Poncho|          191.0|       5|2023-04-25 00:00:00|          1.4|   Credit Card|\n",
      "|       3980|        Poncho|          123.0|       5|2022-12-24 00:00:00|          4.0|   Credit Card|\n",
      "|       3980|        Poncho|          131.0|       3|2023-01-23 00:00:00|          4.6|   Credit Card|\n",
      "|       3980|        Poncho|          185.0|       5|2023-04-01 00:00:00|          3.0|   Credit Card|\n",
      "|       3982|        Poncho|          188.0|       4|2022-11-22 00:00:00|          3.7|   Credit Card|\n",
      "|       3982|         Tunic|          119.0|       4|2023-05-26 00:00:00|          3.4|   Credit Card|\n",
      "|       3985|         Tunic|          161.0|       3|2023-07-26 00:00:00|          1.2|          Cash|\n",
      "|       3986|         Tunic|          126.0|       3|2023-01-30 00:00:00|          4.1|          Cash|\n",
      "|       3987|        Poncho|           36.0|       1|2023-02-26 00:00:00|          3.4|   Credit Card|\n",
      "|       3990|        Poncho|           91.0|       5|2023-04-07 00:00:00|          3.2|   Credit Card|\n",
      "|       3992|        Poncho|          149.0|       1|2023-05-24 00:00:00|          1.5|          Cash|\n",
      "|       4002|        Poncho|           19.0|       3|2023-08-09 00:00:00|          2.3|          Cash|\n",
      "+-----------+--------------+---------------+--------+-------------------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Checking referential integrity: \n",
    "        purchase_history và product\n",
    "        purchase_history và customer\n",
    "'''\n",
    "missing_product = cleand_fas_purchase_df.join(\n",
    "    cleand_product_df,\n",
    "    cleand_fas_purchase_df.item_purchased == cleand_product_df.item,\n",
    "    'left_anti'\n",
    ")\n",
    "missing_product.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+---------+------+-------------+--------------------+------------+-------------------+-------------+------------+\n",
      "|customer_id|first_name|last_name|gender|date_of_birth|               email|phone_number|        signup_date|      address|        city|\n",
      "+-----------+----------+---------+------+-------------+--------------------+------------+-------------------+-------------+------------+\n",
      "|       3964|      Alex|  Johnson|Female|   1972-07-14|robert.williams87...|291-285-3647|2017-09-17 14:04:33|  7255 Oak St|     Phoenix|\n",
      "|       3970|      Alex|    Jones|Female|   1981-10-08|jane.williams34@m...|869-802-7565|2015-07-10 17:08:42|5623 Maple St|     Chicago|\n",
      "|       3995|      Alex|    Jones|  Male|   1997-02-05|sarah.martinez133...|924-800-7391|2019-09-13 14:21:15| 5180 Main St|     Houston|\n",
      "|       4009|      Alex|  Johnson|Female|   1987-09-21|linda.johnson91@m...|178-578-8949|2022-04-10 18:14:58|    45 Oak St|     Houston|\n",
      "|       4032|      Alex|    Jones|  Male|   1992-07-24|jessica.rodriguez...|205-979-9257|2021-02-07 15:34:02|3981 Maple St|     Phoenix|\n",
      "|       4036|      Alex| Williams|Female|   1983-02-06|john.garcia14@mai...|137-725-5082|2016-03-15 00:14:48|  9794 Oak St|    New York|\n",
      "|       4040|      Alex|   Miller|Female|   1986-03-07|emily.williams28@...|490-228-8752|2015-04-25 19:18:24|  9451 Oak St|     Houston|\n",
      "|       4048|      Alex|  Johnson|  Male|   1989-03-07|jane.davis110@mai...|199-178-4514|2020-11-01 08:22:38|2317 Maple St|     Houston|\n",
      "|       4055|      Alex|   Garcia|Female|   1978-02-03|jessica.williams1...|812-801-3722|2020-07-23 21:23:39| 5359 Pine St| Los Angeles|\n",
      "|       4060|      Alex|    Brown|Female|   1988-09-07|alex.miller151@ma...|609-227-4381|2016-06-30 06:38:25|  4809 Oak St|     Houston|\n",
      "|       4071|      Alex|  Johnson|Female|   1982-05-05|robert.smith90@ma...|559-323-3342|2015-09-02 01:37:27|   570 Elm St|    New York|\n",
      "|       4072|      Alex| Williams|Female|   1962-10-24|jane.davis123@mai...|476-629-6304|2022-05-27 15:36:37| 6498 Pine St|     Chicago|\n",
      "|       4074|      Alex|    Smith|Female|   1961-12-20|john.davis51@mail...|736-765-4988|2022-09-01 17:53:48| 9972 Main St|     Chicago|\n",
      "|       4085|      Alex|    Jones|Female|   1963-07-10|robert.rodriguez1...|824-383-3901|2019-11-06 07:45:46| 5348 Main St| Los Angeles|\n",
      "|       4092|      Alex|    Jones| Other|   1987-05-21|john.williams7@ma...|687-991-1638|2018-01-02 08:22:41|5773 Maple St|     Phoenix|\n",
      "|       4099|      Alex|Rodriguez|Female|   1990-07-14|jessica.martinez1...|914-343-4731|2016-04-13 18:23:02| 5485 Pine St|     Houston|\n",
      "|       4103|      Alex|    Smith|  Male|   1965-03-03|sarah.smith107@ma...|830-776-9540|2021-06-04 22:10:24| 6951 Main St|Philadelphia|\n",
      "|       3969|     Emily|   Miller|Female|   1993-01-24|alex.smith53@mail...|461-822-4155|2018-02-02 10:33:46|  5680 Elm St|     Houston|\n",
      "|       3978|     Emily| Martinez|  Male|   1983-03-30|jessica.davis40@m...|482-157-9352|2021-02-14 06:42:43|  5007 Elm St|    New York|\n",
      "|       4001|     Emily|    Davis|Female|   1995-07-23|alex.miller48@mai...|193-864-2827|2021-05-18 07:18:42|  7888 Elm St|Philadelphia|\n",
      "+-----------+----------+---------+------+-------------+--------------------+------------+-------------------+-------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleand_customer_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+---------------+--------+-------------+-------------+--------------+\n",
      "|customer_id|item_purchased|purchase_amount|quantity|date_purchase|review_rating|payment_method|\n",
      "+-----------+--------------+---------------+--------+-------------+-------------+--------------+\n",
      "+-----------+--------------+---------------+--------+-------------+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "missing_customer = cleand_fas_purchase_df.join(\n",
    "    cleand_customer_df,\n",
    "    cleand_fas_purchase_df.customer_id == cleand_customer_df.customer_id ,\n",
    "    'left_anti'\n",
    ")\n",
    "missing_customer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Creation table success!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create purchase_history table\n",
    "sql_statement=[\"\"\"\n",
    "    CREATE TABLE purchase_history \n",
    "    SELECT ph.* \n",
    "    FROM purchase_history_stagging AS ph\n",
    "    JOIN Product AS p \n",
    "    ON ph.item_purchased = p.item;\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    ALTER TABLE purchase_history\n",
    "    ADD CONSTRAINT fk_customer_id \n",
    "    FOREIGN KEY (customer_id) \n",
    "    REFERENCES customer(customer_id) \n",
    "    ON DELETE CASCADE;\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    ALTER TABLE purchase_history\n",
    "    ADD CONSTRAINT fk_item_purchased \n",
    "    FOREIGN KEY (item_purchased) \n",
    "    REFERENCES product(item) \n",
    "    ON DELETE CASCADE;   \n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "message = '✅ Creation table success!' \n",
    "error_message = '❌ Error:'\n",
    "MysqlExecutor().execute(sql_statement, message, error_message)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
